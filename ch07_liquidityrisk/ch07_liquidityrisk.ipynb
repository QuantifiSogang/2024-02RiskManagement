{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c342ca8",
   "metadata": {},
   "source": [
    "# 유동성 위험\n",
    "\n",
    "유동성은 일반적으로 큰 가격 영향 없이 대량의 자산이 판매 가능한 상태인지를 나타내는 정도로 정의되나, 이것이 유동성의 유일한 측면은 아니다. 유동성을 매우 복잡하고 이해하기 어려운 개념이다. 따라서 이 책의 목적상 유동성을 4 가지 특성을 바탕으로 정의하고자 한다.\n",
    "\n",
    "1. 집중도 : 집중도는 자산을 같은 가격에 동시에 거래할 수 있는 능력을 의미한다. 또한 집중도는 거래 도중 발생하는 거래 비용을 의미한다. 거래 비용이 높으면 매수-매도 스프레드가 커지며 그 반대도 성립한다. 따라서 작은 거래 비용은 높은 시장 집중도를 의미한다.\n",
    "\n",
    "2. 즉시성 : 즉시성은 대량의 주문을 거래하는 속도를 의미한다. 이는 금융 시장에 대한 귀중한 정보를 제공한다. 낮은 즉시성은 청산 및 결제 등의 상황에서 오작동이 발생함을 뜻하기 때문이다.\n",
    "\n",
    "3. 깊이 : 이는 다양한 가격으로 풍부한 주문을 처리할 수 있는 많은 수의 구매자와 판매자가 존재하는지를 뜻한다. 많은 거래자가 존재할 때 호가창이 길어지는 것을 생각하면 이해하기 쉽다.\n",
    "\n",
    "4. 탄력성 : 불균형에서 회복하는 시장의 능력을 말한다. 주문 불균형이 빠르게 해소되는 가격 회복 과정으로 이해 가능하다.\n",
    "\n",
    "하지만 각각의 정의가 상호 독립적인 것은 아님에 유의하여야 한다.\n",
    "\n",
    "군집화 분석을 사용하면 유동성의 다차원성을 축소하여 유동성의 척도 가지수를 줄이는 데 도움이 된다. 군집화 분석을 위해서는 가우스 혼합 모델(GMM)과 가우스 혼합 코풀라 모델(GMCM, Gaussian Mixture Copula Model)을 사용할 것이다. GMCM은 상관관계를 고려하기 위해 코풀라 분석을 포함한다는 점에서 GMM의 확장이라 할 수 있다. 우선 다양한 유동성 차원에 기반해 유동성 척도를 식별하는 것부터 시작한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79600860",
   "metadata": {},
   "source": [
    "## 유동성 척도\n",
    "\n",
    "앞서 서술했듯, 유동성은 다양한 척도를 포함한다. 따라서 거래량, 거래비용, 가격 영향, 시장 영향 4가지 차원을 이용해 유동성을 분석해 보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03569e",
   "metadata": {},
   "source": [
    "### 거래량 기반 유동성 척도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f6069",
   "metadata": {},
   "source": [
    "시장이 '깊을 때'. 즉 시장이 다양한 주문을 충족할 수 있는 능력이 있을 때 대규모 주문이 처리된다. 시장에 깊이가 없다면 주문 불균형과 불연속성이 나타난다. 따라서 시장의 깊이를 감안하면 거래량 기반 유동성 척도를 사용해 유동 자산과 비유동 자산을 고려할 수 있게 된다. 이 거래량 기반 유동성 척도는 매수-매도 스프레드와 강한 연관이 있다. 매수-매도 스프레드가 크면 거래량이 적고, 매수-매도 스프레드가 좁으면 거래량이 많다는 의미이다. \n",
    "\n",
    "유동성의 깊이 차원을 적절하게 나타내기 위해 다음과 같은 거래량 기반 척도가 개입된다.\n",
    "1. 유동성 비율\n",
    "2. 휘-회벨 비율\n",
    "3. 회전률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c6a88",
   "metadata": {},
   "source": [
    "#### 유동성 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5561f",
   "metadata": {},
   "source": [
    "유동성 비율은 1%의 가격 변동을 일으키는 데 필요한 거래량의 척도를 측정한다\n",
    "\n",
    "$$ LR_{it}=\\frac{\\Sigma_{t=1}^T P_{it}V_{it}}{\\Sigma_{t=1}^T \\vert PC_{it}\\vert}$$\n",
    "\n",
    "여기서 $P_{it}$는 $t$일의 주식 $i$의 총 가격이고, $V_{it}$는 $t$일의 주식 $i$의 거래량을 나타내며, $ \\vert PC_{it} \\vert $는 $t$일과 $t-1$일에서의 가격 차이의 절대값을 의미한다. 이때, 비율 $LR_{it}$가 높을수록 자산 $i$의 유동성이 높아진다. 이는 높은 거래량인 $P_{it}V_{it}$와 낮은 가격차인 $ \\vert PC_{it} \\vert $가 높은 유동성 수준에 해당함을 의미한다. 거대한 물량이 들어와도 시장 충격이 적다는 것을 의미하기 때문이다. 반대로 가격 변경을 위해 소량이 필요한 경우는 이 자산을 비유동성이라고 한다. 이는 가격 측면에 더 중점을 둔 프레임워크다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e23d69",
   "metadata": {},
   "source": [
    "다음은 코드를 이용해 $LR_{it}$을 계산하는 코드이다. 여기서 주요 변수는 매수(ASKHI), 매도(BIDLO), 시가(OPENPRC)와 거래 가격(PRC), 거래량(VOL), 수익률(RET), 거래량 가중 주식 수익률(VWRETX), 발행 주식수(SHROUT)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c314ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbe8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_data = pd.read_csv('./datasets/bid_ask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9ef45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>EXCHCD</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>OPENPRC</th>\n",
       "      <th>vwretx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031570</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>45.77</td>\n",
       "      <td>47.470</td>\n",
       "      <td>47.08</td>\n",
       "      <td>18761673.0</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>4564000.0</td>\n",
       "      <td>45.960</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031571</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>44.39</td>\n",
       "      <td>46.280</td>\n",
       "      <td>44.49</td>\n",
       "      <td>32254097.0</td>\n",
       "      <td>-0.055013</td>\n",
       "      <td>4564000.0</td>\n",
       "      <td>46.150</td>\n",
       "      <td>-0.021219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1031572</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>45.54</td>\n",
       "      <td>47.570</td>\n",
       "      <td>47.22</td>\n",
       "      <td>35419836.0</td>\n",
       "      <td>0.061362</td>\n",
       "      <td>4564000.0</td>\n",
       "      <td>45.835</td>\n",
       "      <td>0.033399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031573</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>46.75</td>\n",
       "      <td>47.995</td>\n",
       "      <td>47.44</td>\n",
       "      <td>22724997.0</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>4564000.0</td>\n",
       "      <td>47.100</td>\n",
       "      <td>0.009191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031574</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>46.78</td>\n",
       "      <td>48.030</td>\n",
       "      <td>47.74</td>\n",
       "      <td>22721240.0</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>4564000.0</td>\n",
       "      <td>47.800</td>\n",
       "      <td>0.010240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  EXCHCD TICKER      COMNAM  BIDLO   ASKHI    PRC  \\\n",
       "0     1031570  2019-01-02     3.0   INTC  INTEL CORP  45.77  47.470  47.08   \n",
       "1     1031571  2019-01-03     3.0   INTC  INTEL CORP  44.39  46.280  44.49   \n",
       "2     1031572  2019-01-04     3.0   INTC  INTEL CORP  45.54  47.570  47.22   \n",
       "3     1031573  2019-01-07     3.0   INTC  INTEL CORP  46.75  47.995  47.44   \n",
       "4     1031574  2019-01-08     3.0   INTC  INTEL CORP  46.78  48.030  47.74   \n",
       "\n",
       "          VOL       RET     SHROUT  OPENPRC    vwretx  \n",
       "0  18761673.0  0.003196  4564000.0   45.960  0.001783  \n",
       "1  32254097.0 -0.055013  4564000.0   46.150 -0.021219  \n",
       "2  35419836.0  0.061362  4564000.0   45.835  0.033399  \n",
       "3  22724997.0  0.004659  4564000.0   47.100  0.009191  \n",
       "4  22721240.0  0.006324  4564000.0   47.800  0.010240  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liq_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb26d1a",
   "metadata": {},
   "source": [
    "rolling_five는 5일 동안의 매수 가격 계산과 같은 롤링 윈도우 추정을 위해 추가한 데이터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1d7e13",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "rolling_five = []\n",
    "\n",
    "for j in liq_data.TICKER.unique():\n",
    "    for i in range(len(liq_data[liq_data.TICKER == j])):\n",
    "        rolling_five.append(liq_data[i:i+5].agg({'BIDLO': 'min',\n",
    "                                                'ASKHI': 'max',\n",
    "                                                 'VOL': 'sum',\n",
    "                                                 'SHROUT': 'mean',\n",
    "                                                 'PRC': 'mean'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f642423",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_five_df = pd.DataFrame(rolling_five)\n",
    "rolling_five_df.columns = ['bidlo_min', 'askhi_max', 'vol_sum',\n",
    "                           'shrout_mean', 'prc_mean']\n",
    "liq_vol_all = pd.concat([liq_data,rolling_five_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdaec6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_ratio = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        liq_ratio.append((liq_vol_all['PRC'][i+1:i+6] * \n",
    "                          liq_vol_all['VOL'][i+1:i+6]).sum()/\n",
    "                         (np.abs(liq_vol_all['PRC'][i+1:i+6].mean() - \n",
    "                                 liq_vol_all['PRC'][i:i+5].mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a1933",
   "metadata": {},
   "source": [
    "#### 휘-회벨 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a184098",
   "metadata": {},
   "source": [
    "휘-회벨 비율은 LHH로도 잘 알려진 유동성 비율이다.\n",
    "\n",
    "$$L_{HH}=\\frac{P_{max}-P_{min}/P_{min}}{V/(\\bar{P}*shrout)}$$\n",
    "\n",
    "여기서 $P_{max}$와 $P_{min}$은 정해진 기간 동안의 최고가와 최저가를 나타낸다. $\\bar{P}$는 정해진 기간 동안의 평균 종가를 의미한다. 분자에 있는 것($P_{max}-P_{min}/P_{min}$)은 주가의 백분율 변화이며, 거래량은 시가총액으로 나눈다. 즉 $\\bar{P}*shrout$은 시가총액을 의미한다. 이 방법의 장점은 포트폴리오 뿐만 아니라 단일 종목에도 적용할 수 있다는 사실이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e6e3d",
   "metadata": {},
   "source": [
    "다음은 휘-회벨 비율을 계산하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbe3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lhh = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        Lhh.append((liq_vol_all['PRC'][i:i+5].max() - \n",
    "                    liq_vol_all['PRC'][i:i+5].min()) /  \n",
    "                   liq_vol_all['PRC'][i:i+5].min() /  \n",
    "                   (liq_vol_all['VOL'][i:i+5].sum() / \n",
    "                    liq_vol_all['SHROUT'][i:i+5].mean() * \n",
    "                    liq_vol_all['PRC'][i:i+5].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4682eb",
   "metadata": {},
   "source": [
    "#### 회전률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b403b",
   "metadata": {},
   "source": [
    "회전률은 기본적으로 발행 주식 수에 대한 거래 주식 수의 비율이다.\n",
    "\n",
    "$$LR_{it}=\\frac{1}{D_{it}} \\frac{\\Sigma_{t=1}^T Vol_{it}}{\\Sigma_{t=1}^T shrout_{it}}$$\n",
    "\n",
    "여기서 $D_{it}$는 거래일 수, $Vol_{it}$는 시간 t에 거래된 주식 수, $shrout_{it}$는 시간 t에 발행된 주식 수를 의미한다. Amihud와 Mandelson(1986b)에 의하면 회전률과 주식의 유동성 비용은 음의 상관관계를 가지고 있다고 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02f3a8",
   "metadata": {},
   "source": [
    "다음은 회전률을 계산하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b825b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_ratio = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        turnover_ratio.append((1/liq_vol_all['VOL'].count()) * \n",
    "                              (np.sum(liq_vol_all['VOL'][i:i+1]) / \n",
    "                               np.sum(liq_vol_all['SHROUT'][i:i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2edf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['liq_ratio'] = pd.DataFrame(liq_ratio)\n",
    "liq_vol_all['Lhh'] = pd.DataFrame(Lhh)\n",
    "liq_vol_all['turnover_ratio'] = pd.DataFrame(turnover_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92d3a9",
   "metadata": {},
   "source": [
    "### 거래 비용 기반 유동성 척도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8073bb0",
   "metadata": {},
   "source": [
    "거래 비용은 투자자가 부담해야 하는 비용을 의미한다. 즉 거래의 집행과 관련된 모든 비용을 뜻한다. 거래 비용은 명시적 비용과 암묵적 비용으로 구분이 가능한데, 전자는 주문 처리, 세금 및 중계 수수료 등에 관련되어 있으며, 후자는 매수-매도 스프레드, 실행 시기 등과 같은 잠재 비용에 연관되어 있다. 높은 거래 비용은 투자자의 거래를 방해하고 이는 다시 시장의 구매자와 판매자의 수를 줄여 시장이 '얕아지게'하는 주요 원인이 된다. 또한 거래 비용이 낮고 구매자와 판매자가 풍부해지면 짧은 시간에 다량의 주문이 처리된다는 뜻이므로 즉시성과도 연관이 된다.\n",
    "\n",
    "호가 스프레드는 거래 비용에 대한 널리 인정되는 대용품이다. 매수-매도 스프레드는 자산을 현금으로 전환하는 용이성을 결정할 수 있는 유동성의 좋은 지표이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5acb4",
   "metadata": {},
   "source": [
    "#### 명목과 유효 메수-매도 스프레드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d80f8",
   "metadata": {},
   "source": [
    "명목 스프레드는 거래 완료 비용, 즉 매수-매도 스프레드의 차이를 측정한다. 퍼센트 명목 스프레드는 다음과 같이 계산된다.\n",
    "\n",
    "$$퍼센트 명목 스프레드 = \\frac{P_{ask}-P_{bid}}{P_{mid}}$$\n",
    "\n",
    "여기서 $P_{ask}$는 주식의 매수 호가, $P_{bid}$는 주식의 매도 호가를 의미한다. \n",
    "\n",
    "유효 매수-매도 스프레드의 경우, 거래가 명목 내 또는 외에서 발생하는 경우 거래 비용을 더 정확히 측정한다고 알려져 있으며, 실제 거래 가격을 기반으로 해 백분율 기준으로 계산하는 형태를 띄고 있다.\n",
    "\n",
    "$$유효 스프레드 = \\frac{2\\vert P_t-P_{mid} \\vert}{P_{mid}}$$\n",
    "\n",
    "여기서 $P_t$는 해당 주식의 거래 가격이며 $P_{mid}$는 거래 시점에 유효한 매수-메도 호가의 중간점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08083e55",
   "metadata": {},
   "source": [
    "다음은 명목 스프레드와 유효 스프레드를 계산하는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['mid_price'] = (liq_vol_all.ASKHI + liq_vol_all.BIDLO) / 2\n",
    "liq_vol_all['percent_quoted_ba'] = (liq_vol_all.ASKHI - \n",
    "                                    liq_vol_all.BIDLO) / \\\n",
    "                                    liq_vol_all.mid_price\n",
    "liq_vol_all['percent_effective_ba'] = 2 * abs((liq_vol_all.PRC - \n",
    "                                               liq_vol_all.mid_price)) / \\\n",
    "                                               liq_vol_all.mid_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ca49a",
   "metadata": {},
   "source": [
    "#### Roll's Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae35684",
   "metadata": {},
   "source": [
    "##### Random walk model of security prices\n",
    "\n",
    "시간 $t$에서 거래되는 가격 $p_t$를 가정하자. 여기서 시간 인덱스 $t$는 한 시간 간격이 될 수 있고, 일 분이 될 수도 있으며, 하루가 될 수도 있다. 이 시간을 앞으로 캘린터 타임(calander time)이라고 부르도록 한다. random walk를 따르는 가격 계열 p_t는 다음을 따른다고 가정한다.\n",
    "\n",
    "\n",
    "$$\n",
    "p_t = p_{t - 1} + \\mu + u_t\n",
    "$$\n",
    "\n",
    "여기서 $u_t, t \\in \\{0,\\dots, T\\}$인 white noise 계열이고 iid 프로세스를 따르는 random variable이다. 직관적으로 보자면, 새로운 정보가 시장에 도달하면 가격은 변화한다. $\\mu$는 시장의 기대 가격 변화 수준이다 $(E[\\Delta p_t])$. 만약 시장의 기대가 가격이 상승하거나 하락하지 않는 횡보장 혹은 정적인 상태라면 $\\mu = 0$이 될 것이다. 이 상황에서 가격 $p_t = p_{t-1} + u_t$이기 때문에 확률보행 과정을 따른다. 따라서 이 경우, 가격의 예측은 전혀 불가능하다(이 과정을 martingale 과정이라고 부른다).\n",
    "\n",
    "그러나, 현실적으로 가격이 확률보행 과정을 완벽히 따르는 것은 보기 힘들다. 당장에 증권 시장에서는 판매자와 구매자 뿐만 아니라 정보 기반 거래자와 유동성 공급자, 브로커가 존재하며 중간 매개자들은 거래 유동성을 원활히 하고 매칭을 해 주는 대신 수수료를 취한다. 따라서, bid price, ask price가 동시에 존재하는 시장이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05d8ad",
   "metadata": {},
   "source": [
    "##### The Roll Model of bid, ask, and Transaction prices\n",
    "Roll은 bid price와 ask price 사이의 중간 가격 계열 $m_t$를 고려하였다. 추세가 없는 random walk process $\\{m_t\\}$를 다음과 같이 가정해 보자.\n",
    "\n",
    "$$\n",
    "m_t = m_{t-1} + u_t\n",
    "$$\n",
    "\n",
    "중간 가격의 변화분 $\\Delta m_t = m_t - m_{t-1}$은 정규 분포로부터 독립적이고 동일하게 추출된다.\n",
    "\n",
    "$$\n",
    "\\Delta m_t \\sim N(0, \\sigma_u^2)\n",
    "$$\n",
    "\n",
    "관측된 가격 $\\{p_t\\}$는 중간 가격 계열 $\\{m_t\\}$에 스프레드가 더해진 순차적 거래에 대한 결과이다.\n",
    "\n",
    "$$\n",
    "p_t = m_t + b_tc\n",
    "$$\n",
    "\n",
    "여기서 $c$는 bid-ask spread의 절반이고 $b_t \\in \\{-1, 1\\}$은 공격적인 거래자의 거래 방향(side)이다. Roll Model은 매수와 매도가 발생할 확률이 동일하고(각각 $P[b_t = 1] = P[b_t = -1] = \\frac{1}{2}$), 계열 독립 $(E[b_t b_{t-1}] = 0)$이며, $E[b_tu_t] = 0$으로 가정한다. 이런 가정들 하에서 $c$와 $\\sigma_u^2$의 값은 다음과 같이 도출할 수 있다.\n",
    "\n",
    "$$\n",
    "\\sigma^2[\\Delta p_t] = E\\left[ (\\Delta p_t)^2 \\right] - \\left(E[(\\Delta p_t)] \\right)^2 = 2c^2 + \\sigma_u^2\n",
    "$$\n",
    "$$\n",
    "\\sigma\\left[\\Delta p_t, \\Delta p_{t-1}\\right] = - c^2\n",
    "$$\n",
    "\n",
    "위 식을 풀어 보면 spread추정량 $c = \\sqrt{\\max\\{0, -\\sigma[\\Delta p_t, \\Delta p_{t-1}]\\}}$과 변동성 추정량 $\\sigma_u^2 = \\sigma^2[\\Delta p_t] + 2\\sigma[\\Delta p_t, \\Delta p_{t-1}]$의 결과를 얻을 수 있다. 즉, bid-ask spread는 가격 변화량 계열의 공분산에 대한 함수이고, 시장 미시구조적 잡음을 제거한 관측되지 않은 가격의 잡음은 관측된 잡음$(\\sigma^2[\\Delta p_t])$과 가격변화량 계열의 공분산의 함수$(\\sigma[\\Delta p_t, \\Delta p_{t-1}])$이다.\n",
    "\n",
    "Roll Model에서 추정된 spread $c$는 다음과 같은 의미를 가진다.\n",
    "\n",
    "1. 거래 비용의 척도: Roll 모델로 추정된 스프레드는 거래를 실행할 때 발생하는 시장 참여자의 평균 거래 비용을 나타낸다. 이 비용은 주로 매수자와 매도자 사이의 정보 비대칭, 주문 실행 리스크, 시장 유동성의 부족 등으로 인해 발생한다.\n",
    "2. 시장 유동성의 지표: 낮은 스프레드는 높은 시장 유동성을 의미하고, 투자자들이 상대적으로 낮은 거래 비용으로 자산을 사고파는 것이 가능함을 나타낸다. 반면, 높은 스프레드는 낮은 유동성을 나타내며, 투자자들이 더 높은 거래 비용을 부담해야 함을 의미한다. 즉, 스프레드가 벌어질 수록 시장의 불균형이 발생한다는 것을 간접적으로 알 수 있다.\n",
    "3. 정보 효율성의 측정: Roll 모델의 스프레드 추정치는 시장의 정보 효율성을 간접적으로 평가하는 데 사용될 수 있다. 스프레드가 넓을수록 시장 참여자들 사이에 더 많은 정보 비대칭이 존재한다고 해석할 수 있다. 즉 스프레드가 작을수록 정보의 공개된 정도가 크다는 의미이다.\n",
    "\n",
    "Roll Model이 강력한 또 한가지 이유는 주식시장 뿐만이 아닌 거래가 적은 Asset based Security market 혹은 real estate 거래에서도 시장 불균형의 척도로써 사용이 가능하기 때문이다. 다만, Roll Model에서도 약점은 존재하는데 거래 비용 외의 가격 변동 원인 무시, 시장의 모든 참여자가 같은 스프레드를 경험한다는 가정이 현실과 동떨어져 있다는 점이다. 또한, mid price series $\\{m_t\\}$가 iid 계열이라는 점도 비현실적인 가정인 것도 고려해야 한다. 하지만 시장이 효율적이고 관찰된 가격변동의 분포 확률이 정상성을 띈다고 가정하면 롤의 스프레드는 유동성에 대한 좋은 대용물이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05cb15",
   "metadata": {},
   "source": [
    "다음은 롤의 스프레드를 계산하는 코드이다. 여기서는 공분산이 양의 값을 갖는 경우 해리스의 접근 방식을 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e37d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['price_diff'] = liq_vol_all.groupby('TICKER')['PRC']\\\n",
    "                            .apply(lambda x:x.diff())\n",
    "liq_vol_all.dropna(inplace=True)\n",
    "roll = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "     for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        roll_cov = np.cov(liq_vol_all['price_diff'][i:i+5], \n",
    "                          liq_vol_all['price_diff'][i+1:i+6])\n",
    "        if roll_cov[0,1] < 0:\n",
    "            roll.append(2 * np.sqrt(-roll_cov[0, 1]))\n",
    "        else:\n",
    "             roll.append(2 * np.sqrt(np.abs(roll_cov[0, 1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472c49c",
   "metadata": {},
   "source": [
    "#### Corwin and Schultz (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a55c14e",
   "metadata": {},
   "source": [
    "Corwin, Schultz는 Beckers의 연구를 기반으로 고가와 저가로부터 매매 호가 스프레드 추정량을 소개했다. 그 추정량은 두 가지 원칙에 기반을 두고 있다. 첫째, 고가는 거의 항상 매도 호가에 매치되고, 저가는 매수 호가에 매치된다는 것이다. 고가 대비 저가의 비율은 근본적인 변동성과 bid-ask spread를 반영한다. 둘째, 변동성에 기인한 bid-ask 비율의 구성 요소는 두 관측값 사이에 경과한 시간에 비례해 증가한다.\n",
    "\n",
    "Corwin, Schultz는 매매 호가 스프레드를 가격의 퍼센티지로 다음과 같이 계산할 수 있다는 것을 보였다.\n",
    "\n",
    "$$S_t = \\frac{2(e^{\\alpha_t}-1)}{1+e^{\\alpha_t}}$$\n",
    "\n",
    "여기서\n",
    "\n",
    "$$\\alpha_t = \\frac{\\sqrt{2\\beta_t} - \\sqrt{\\beta_t}}{3 - 2\\sqrt{2}} - \\sqrt{\\frac{\\gamma_t}{3-2\\sqrt{2}}}$$\n",
    "$$\\beta_t = E \\Big[\\sum_{j=0}^1 \\Big[\\log \\Big(\\frac{H_{t-j}}{L_{t-j}} \\Big) \\Big]^2\\Big]$$\n",
    "$$\\gamma_t = \\Big[\\log \\Big(\\frac{H_{t-1, t}}{L_{t-1, t}}\\Big) \\Big]^2$$\n",
    "\n",
    "$H_{t-1,t}$는 두 기간에 걸친 고가이고, $L_{t-1,t}$는 두 기간에 걸친 저가이다. Corwin-Schultz의 식에서는 변동성이 보이지 않는데, 이는 고가/저가 추정량으로 대체되었기 때문이다. 이 모델로써 벡커-파킨슨 변동성을 유도할 수 있다. 이 스프레드 추정량은 중앙 집중된 주문 호가창이 없고, 거래가 경쟁 희망 매수 호가(Bids Wanted In Competition)에 의해 일어나는 회사채 시장에서 특히 유용하다. 그 결과 특성인 bid-ask spread는 moving average window에 걸쳐 반복적으로 계산한 후 Kalman Filter를 이용해 평활화할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12abad",
   "metadata": {},
   "source": [
    "다음은 코윈 슐츠 스프레드를 계산하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec507fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        gamma.append((max(liq_vol_all['ASKHI'].iloc[i+1], \n",
    "                          liq_vol_all['ASKHI'].iloc[i]) - \n",
    "                      min(liq_vol_all['BIDLO'].iloc[i+1], \n",
    "                          liq_vol_all['BIDLO'].iloc[i])) ** 2)\n",
    "        gamma_array = np.array(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        beta.append((liq_vol_all['ASKHI'].iloc[i+1] - \n",
    "                     liq_vol_all['BIDLO'].iloc[i+1]) ** 2 + \n",
    "                    (liq_vol_all['ASKHI'].iloc[i] - \n",
    "                     liq_vol_all['BIDLO'].iloc[i]) ** 2)\n",
    "        beta_array = np.array(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6da937",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ((np.sqrt(2 * beta_array) - np.sqrt(beta_array)) / \n",
    "       (3 - (2 * np.sqrt(2)))) - np.sqrt(gamma_array / \n",
    "                                         (3 - (2 * np.sqrt(2))))\n",
    "CS_spread = (2 * np.exp(alpha - 1)) / (1 + np.exp(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all = liq_vol_all.reset_index()\n",
    "liq_vol_all['roll'] = pd.DataFrame(roll)\n",
    "liq_vol_all['CS_spread'] = pd.DataFrame(CS_spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ee3e6",
   "metadata": {},
   "source": [
    "### Price Based Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8155f91",
   "metadata": {},
   "source": [
    "여기서는 가격이 거래량과 회전률에 대해 민감한 정도를 측정할 수 있는 가격 영향 기반 유동성 측정 방법론을 소개한다. 만일 시장이 새로운 질서(주문)에 빠르게 반응해 시장의 불균형이 바로잡힌다면 해당 시장은 탄력적인 시장이 된다. 따라서 거래량 또는 회전율이 주어질 때 높은 가격 조정이 이뤄지는 경우 높은 탄력성을 의미하며, 그 반대도 성립힌다.\n",
    "\n",
    "여기서는 세가지 가격 영향 기반 유동성 측정 방법론을 소개한다.\n",
    "\n",
    "1. 아미후드의 비유동성 추정\n",
    "2. 플로락키스, 안드로스, 알렉산드로스의 가격 영향 비율\n",
    "3. 거래 탄력성 계수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e9e6f",
   "metadata": {},
   "source": [
    "#### Amihud의 비유동성\n",
    "\n",
    "Amihud(2002)는 절대 수익률과 비유동성 사이의 양의 관계를 연구했다. 그는 거래량의 1달러에 연관된 일별 가격 반응을 계산한 값이 가격 충격의 대리 척도라고 주장했다. 이 아이디어를 구현하는 방법 중 하나는 다음과 같다\n",
    "\n",
    "$$ILLIQ=\\frac{1}{D_{it}} \\Sigma_{d=1}^{D_it}\\frac{\\vert R_{itd}\\vert}{V_{itd}}$$\n",
    "\n",
    "여기서 $R_{itd}$는 t월 d일의 주식 수익률, $V_{itd}$는 t월 d일의 달러 거래량, $D$는 t월 관찰 일수이다.\n",
    "\n",
    "아미후드 측정은 가격 영향을 포착하기 위해 일일 거래량 대비 수익 비율의 절대값을 사용하는 간단한 구성을 가지고 있고, 이 측정값은 예상 주가 수익률과 강한 양의 관계를 가지고 있다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8723e",
   "metadata": {},
   "source": [
    "다음은 아미후드 비유동성 측정 방법을 구현한 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvol = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        dvol.append((liq_vol_all['PRC'][i:i+5] *\n",
    "                     liq_vol_all['VOL'][i:i+5]).sum())\n",
    "liq_vol_all['dvol'] = pd.DataFrame(dvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35252634",
   "metadata": {},
   "outputs": [],
   "source": [
    "amihud = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        amihud.append((1 / liq_vol_all['RET'].count()) * \n",
    "                      (np.sum(np.abs(liq_vol_all['RET'][i:i+1])) / \n",
    "                              np.sum(liq_vol_all['dvol'][i:i+1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e003380",
   "metadata": {},
   "source": [
    "#### 플로락키스, 안드로스, 알렉산드로스의 가격 영향 비율\n",
    "\n",
    "플로락키스, 안드로스, 알렉산드로스는 아미후드 비유동성 비율을 개선하는 것을 목표로 하고 새로운 유동성 척도인 수익률 대 회전률(RtoTR) 비율을 제시하였다. 저자가 제사한 아미후드 측정의 단점은 다음과 같다.\n",
    "\n",
    "1. 시가총액이 다른 주식 간의 비교가 어렵다.\n",
    "\n",
    "2. 투자자의 보유 기간을 무시한다.\n",
    "\n",
    "이를 보완하는 RtoTR은 다음과 같은 구조를 지닌다.\n",
    "\n",
    "$$RtoTR = \\frac{1}{D_{it}}\\Sigma_{d=1}^{D_it}\\frac{\\vert R_{itd} \\vert}{TR_{itd}}$$\n",
    "\n",
    "여기서 $TR_{itd}$는 t월 d일의 i의 turnover ratio를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568aa58e",
   "metadata": {},
   "source": [
    "다음은 플로락키스, 안드로스, 알렉산드로스의 가격 영향 비율을 게산하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "florackis = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        florackis.append((1 / liq_vol_all['RET'].count()) * \n",
    "                         (np.sum(np.abs(liq_vol_all['RET'][i:i+1]) / \n",
    "                                 liq_vol_all['turnover_ratio'][i:i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4540974",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['vol_diff_pct'] = liq_vol_all.groupby('TICKER')['VOL']\\\n",
    "                              .apply(lambda x: x.diff()).pct_change()\n",
    "liq_vol_all['price_diff_pct'] = liq_vol_all.groupby('TICKER')['PRC']\\\n",
    "                              .apply(lambda x: x.diff()).pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f63e511",
   "metadata": {},
   "source": [
    "#### 거래의 탄력성 계수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98849f6",
   "metadata": {},
   "source": [
    "거래의 탄력성 계수(CET, Coefficient of Elasticity of Trading)는 단위 시간당 거래 수 및 주문과 같은 시간 관련 유동성 측정의 단점을 보완하기 위해 만들어진 측정 지표이다. 이 척도는 시장의 즉각성이 유동성 수준에 영향을 미치는 정도를 평가하기 위해 사용된다.\n",
    "\n",
    "시장 즉각성과 CET는 거래량의 가격 탄력성을 측정하기 때문에 함께 사용되며, 가격이 거래량에 반응하는 경우, 즉 탄력적이라면 더 큰 수준의 시장 즉각성을 의미한다.\n",
    "\n",
    "$$CET=\\frac{ \\% \\Delta V}{ \\% \\Delta P}$$\n",
    "\n",
    "여기서 $\\% \\Delta V$는 거래량의 퍼센트 변화율을 나타내며, $\\% \\Delta P$는 가격의 퍼센트 변화율을 나타낸다. 다음은 CET를 구현한 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46df604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cet = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        cet.append(np.sum(liq_vol_all['vol_diff_pct'][i:i+1])/\n",
    "                   np.sum(liq_vol_all['price_diff_pct'][i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbfa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['amihud'] = pd.DataFrame(amihud)\n",
    "liq_vol_all['florackis'] = pd.DataFrame(florackis)\n",
    "liq_vol_all['cet'] = pd.DataFrame(cet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33015fc",
   "metadata": {},
   "source": [
    "## Market Impact Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f799110",
   "metadata": {},
   "source": [
    "미지의 정보가 투자자를 오도하고 의도치 않은 결과를 초래할 수 있다는 점에서 시장 데이터에서 정보 출처를 식별하는 것은 매우 중요한 일이다. 예컨데 시장에서 발생하는 가격 급등은 개별 주식에서 발생하는 것과 동일한 정보를 제공하지 않는다. 즉 가격 움직임을 적절하게 포착하는 방식으로 새로운 정보 소스를 식별해야 한다.\n",
    "\n",
    "이를 위해 CAPM을 바탕으로 체계적 위험과 비체계적 위험을 구분한다. CAPM의 기울기 계수는 체계적 위험을 나타내며, 비체계적 위험은 시장 위험이 제거되는 한 개별 주식에 귀속된다.\n",
    "\n",
    "휘-회벨은 다음 접근 방식을 사용한다.\n",
    "\n",
    "$$R_i=\\alpha+\\beta R_m +u_i$$\n",
    "\n",
    "여기서 $R_i$는 i번째 주식의 일별 수익률이고, $u_i$는 비체계적 위험이다.\n",
    "\n",
    "이를 바탕으로 잔차 $u_i$를 추정한 뒤 거래량 $V_i$에 대해 회귀분석하면 $V_i$의 계수는 고유 위험이라고도 하는 관련 주식 유동성의 수준을 보여준다.\n",
    "\n",
    "$$u_i^2=\\gamma _1+\\gamma _2 V_i + e_i$$\n",
    "\n",
    "여기서 $u_i^2$은 잔차 제곱 항을 나타내고 $V_i$는 거래량의 일 백분율 변화를 나타낸다. 그리고 $e_i$는 잔차 항이다. $\\gamma _2$가 커질수록 더 큰 가격 움직임을 의미하며, 이는 주식의 유동성에 대한 정보를 제공한다. $\\gamma _2$가 작을수록 주어지는 거래량 변화에 대한 비체계적 위험의 변화가 크지 않다는 의미이므로 유동성 수준이 높아진다는 사실을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55283a8c",
   "metadata": {},
   "source": [
    "다음은 해당 내용을 계산하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4255c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['VOL_pct_change'] = liq_vol_all.groupby('TICKER')['VOL']\\\n",
    "                                .apply(lambda x: x.pct_change())\n",
    "liq_vol_all.dropna(subset=['VOL_pct_change'], inplace=True)\n",
    "liq_vol_all = liq_vol_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61843be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsys_resid = []\n",
    "\n",
    "for i in liq_vol_all.TICKER.unique():\n",
    "    X1 = liq_vol_all[liq_vol_all['TICKER'] == i]['vwretx']\n",
    "    y = liq_vol_all[liq_vol_all['TICKER'] == i]['RET']\n",
    "    ols = sm.OLS(y, X1).fit()\n",
    "    unsys_resid.append(ols.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_impact = {}\n",
    "\n",
    "for i, j in zip(liq_vol_all.TICKER.unique(), \n",
    "                range(len(liq_vol_all['TICKER'].unique()))):\n",
    "    X2 = liq_vol_all[liq_vol_all['TICKER'] == i]['VOL_pct_change']\n",
    "    ols = sm.OLS(unsys_resid[j] ** 2, X2).fit()\n",
    "    print('***' * 30)\n",
    "    print(f'OLS Result for {i}')\n",
    "    print(ols.summary())\n",
    "    market_impact[j] = ols.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "append1 = market_impact[0].append(market_impact[1])\n",
    "liq_vol_all['market_impact'] = append1.append(market_impact[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d481a1",
   "metadata": {},
   "source": [
    "이제 현재까지 다뤄 본 모든 유동성 측정의 요약 통계량을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['vol_diff_pct', 'price_diff_pct', 'price_diff',\n",
    "        'VOL_pct_change', 'dvol', 'mid_price']\n",
    "liq_measures_all = liq_vol_all.drop(liq_vol_all[cols], axis=1)\\\n",
    "                   .iloc[:, -11:]\n",
    "liq_measures_all.dropna(inplace=True)\n",
    "liq_measures_all.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e951cc",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623cb8b8",
   "metadata": {},
   "source": [
    "유동성 측정으로 구성된 데이터는 다차원을 가지고 있다. 즉, 여러 높은 확률이 존재하며 전체에 대해 잘 적합되는 모델을 찾아야 한다. 요약하자면, 모든 유동성 척도를 포함하는 하나의 데이터 셋을 획득하였다. 하지만 우리가 데이터에 대한 레이블을 모른다고 가정하면 우리는 레이블을 모른 채 다양한 분포를 분류할 수 있는 모델이 필요하다. 이 모델이 바로 GMM이다.\n",
    "\n",
    "어떤 유동성 데이터를 쓰냐에 따라 전혀 다른 결과가 나온다. 예를 들어 trading volume과 spread는 둘 모두 시장에 정보가 개입하였을 때 양의 상관관계를 갖는다. 하지만 trading volume이 높으면 일반적으로 유동성이 높다고 여겨지고, spread가 높다면 유동성이 낮다고 여겨진다. 즉 동일한 상황에 대해 두 전혀 상반된 지표가 일치하는 결과를 산출한다는 의미이다. 다른 예시로는 price volatility가 있는데, price volatility는 liquidity가 높아도 낮고, liquidity가 매우 부족해도 낮다. 따라서 시장의 깊이를 확인하기 위해서는 유동성의 다양한 측면에 초점을 맞춰야 한다. GMM은 이를 해결하기 위한 좋은 도구이다.\n",
    "\n",
    "간단히 서술하자면 시장이 높은 변동성과 일치하는 호황기를 경험하고 있다면 거래량과 거래 비용에 기반한 평가가 좋은 선택이 될 것이며, 시장에 가격 불연속성이 존재한다면 가격 기반 평가가 최적의 선택이 될 것이다. 즉, 측정된 유동성 측도를 혼합하여 전체적인 유동성을 평가하는 것이 더 잘 작동할 가능성이 존재한다.\n",
    "\n",
    "반데르플라스에 따르면 K-Mean이 효율적으로 작동하려면 클러스터 모델이 원형 특성을 가져야 하나, 많은 재무 변수는 K-mean 모델을 이용해 모델링 하기 어려운 비원형 모양을 나타낸다. 따라서 확률적 특성을 가진 GMM은 이런 데이터를 모델링하기 위한 좋은 수단이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d212c",
   "metadata": {},
   "source": [
    "#### 가우시안 혼합모형(Gaussian Mixture Model)\n",
    "\n",
    "$K$-클래스 카테고리 확률변수 $Z$가 있다고 하자. 확률분포함수는 다음과 같다.\n",
    "\n",
    "$$ p(z=k) = \\pi_k $$\n",
    "\n",
    "실수값을 출력하는 확률변수 $X$는 확률변수 $Z$의 표본값 $k$에 따라 기댓값 $\\mu_k$, 분산 $\\Sigma_k$이 달라진다.\n",
    "\n",
    "$$ p(x \\mid z) = \\mathcal{N}(x\\mid \\mu_k, \\Sigma_k) $$\n",
    "\n",
    "이를 결합하면\n",
    "\n",
    "$$ p(x) = \\sum_Z p(z)p(x\\mid z) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x \\mid \\mu_k, \\Sigma_k) $$\n",
    "\n",
    "이 된다.\n",
    "\n",
    "실수값을 출력하는 확률변수 $X$가 $K$-클래스 카테고리 확률변수 $Z$의 값에 따라 다른 기댓값과 분산을 가지는 복수의 가우시안 정규분포들로 이루어진 모형을 가우시안 혼합(Gaussian Mixture) 모형이라고 한다.\n",
    "\n",
    "단 가우시안 혼합모형에서 카테고리 확률변수 $Z$의 값을 알 수가 없다. 즉 관측되지 않는다고 가정한다. 이렇게 관측 데이터가 보이지 않는, 즉 내부에 숨겨진(latent) 확률 변수를 포함하는 모형을 잠재변수모형(latent variable model)이라고 한다. 잠재변수는 혼합모형처럼 카테고리값이 될 수도 있고 다른 모형에서는 실수값도 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4a701",
   "metadata": {},
   "source": [
    "#### GMM의 모수 추정 방법\n",
    "\n",
    "데이터로부터 가우시안 혼합모형의 모수를 추정한다는 것은 관측되지 않는 카테고리 분포의 확률분포와 각각의 카테고리에서의 가우시안 정규분포 모수를 모두 추정하는 것을 말한다. 이 때 어려운 점은 확률분포함수가 선형대수 방법으로 쉽게 구할 수 없는 복잡한 형태를 가진다는 점이다. \n",
    "\n",
    "$N$개의 데이터에 대한 $X$의 확률분포는 \n",
    "\n",
    "$$ p(x) = \\prod_{i=1}^N p(x_i) = \\prod_{i=1}^N \\sum_{z_i} p(x_i,z_i) = \\prod_{i=1}^N \\sum_{z_i} p(z_i)p(x_i\\mid z_i)  = \\prod_{i=1}^N \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x_i\\mid \\mu_k, \\Sigma_k) $$\n",
    "\n",
    "이고 로그를 취하면\n",
    "\n",
    "$$  \\log p(x) = \\sum_{i=1}^N \\log \\left( \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x_i\\mid \\mu_k, \\Sigma_k) \\right) $$\n",
    "\n",
    "이다. 두 식 모두 미분값이 0이 되는 모수값을 쉽게 구할 수 없다.\n",
    "\n",
    "만약 데이터 $x_i$가 어떤 카테고리 $z_i$에 속하는지를 안다면 같은 카테고리에 속하는 데이터만 모아서 카테고리 확률분포 $\\pi_k$도 알 수 있고 가우시안 정규분포의 모수 $\\mu_k, \\Sigma_k$도 쉽게 구할 수 있을 것이다. 하지만 실제로는 데이터 $x_i$가 가지고 있는 카테고리 값 $z_i$를 알 수가 없기 때문에 위  확률분포함수 $p(x)$를 최대화하는 $\\pi_k$와 $\\mu_k, \\Sigma_k$를 비선형 최적화를 통해 구해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499c419",
   "metadata": {},
   "source": [
    "이를 위해 사용하는 방법이 바로 EM(Expectation-Maximization) 알고리즘이다. \n",
    "\n",
    "혼합모형의 모수추정에서 중요한 역할을 하는 것 중의 하나가 바로 각 데이터가 어떤 카테고리에 속하는가를 알려주는 조건부 확률 $p(z\\mid x)$ 값이다. 이 값을 responsibility라고 한다.\n",
    "\n",
    "$$ \n",
    "\\pi_{ik} \\newline \\newline\n",
    "$$\n",
    "\n",
    "$$\n",
    "= p(z_i=k\\mid x_i) \\newline \\newline\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\dfrac{p(z_i=k)p(x_i\\mid z_i=k)}{p(x_i)} \\newline\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\dfrac{p(z_i=k)p(x_i\\mid z_i=k)}{\\sum_{k=1}^K p(x_i,z_i=k)} \\newline\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\dfrac{p(z_i=k)p(x_i\\mid z_i=k)}{\\sum_{k=1}^K p(z_i=k)p(x_i\\mid z_i=k)} \n",
    "$$\n",
    "\n",
    "가우시안 혼합모형의 경우 다음과 같이 정리할 수 있다. \n",
    "\n",
    "$$ \n",
    "\\pi_{ik} = \\dfrac{\\pi_k \\mathcal{N}(x_i\\mid \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_i\\mid \\mu_k, \\Sigma_k)} \n",
    "$$\n",
    "\n",
    "\n",
    "이 식은 모수로부터 responsibility를 추정한다.\n",
    "\n",
    "$$ (\\pi_k, \\mu_k, \\Sigma_k) \\;\\; \\implies \\;\\; \\pi_{ik} $$\n",
    "\n",
    "\n",
    "$\\pi_{ik}$는 $i$번째 데이터 $x_i$가 카테고리 $k$에서 만들어졌을 확률을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4df45",
   "metadata": {},
   "source": [
    "이제 로그-결합확률분포함수를 최대화한다.\n",
    "\n",
    "우선 $\\mu_k$로 미분하여 0이 되도록 하는 방정식을 만들면 다음과 같다.\n",
    "\n",
    "$$ 0 = - \\sum_{i=1}^N \\dfrac{p(z_i=k)p(x_i\\mid z_i=k)}{\\sum_{k=1}^K p(z_i=k)p(x_i\\mid z_i=k)} \\Sigma_k (x_i - \\mu_k ) $$\n",
    "\n",
    "이를 정리하면,\n",
    "\n",
    "$$ \\sum_{i=1}^N \\pi_{ik} (x_i - \\mu_k ) = 0$$\n",
    "\n",
    "$$ \\mu_k = \\dfrac{1}{N_k} \\sum_{i=1}^N \\pi_{ik} x_i $$\n",
    "\n",
    "위 식에서 \n",
    "$$ N_k = \\sum_{i=1}^N \\pi_{ik} $$\n",
    "\n",
    "이고 $k$ 카테고리에 속하는 데이터의 수와 비슷한 의미를 가진다. 즉 $\\mu_k$는 $k$카테고리에 속하는 데이터의 샘플 평균과 같의 의미이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed9064",
   "metadata": {},
   "source": [
    "마찬가지로 로그-결합확률분포함수를 $\\Sigma_k$로 미분하여 최대화하는 모수값을 구하면 다음과 같다.\n",
    "\n",
    "$$ \\Sigma_k = \\dfrac{1}{N_k} \\sum_{i=1}^N \\pi_{ik} (x_i-\\mu_k)(x_i-\\mu_k)^T $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c34a7",
   "metadata": {},
   "source": [
    "마지막으로 로그-결합확률분포함수를 $\\pi_k$로 미분하여 최대화하는 모수값을 구해야 하는데 이 때 카테고리값의 모수가 가지는 제한 조건으로 인해 Lagrange multiplier 를 추가해야 한다.\n",
    "\n",
    "$$ \\log p(x) + \\lambda \\left(\\sum_{k=1}^K \\pi_k - 1 \\right) $$\n",
    "\n",
    "\n",
    "이를 $\\pi_k$로 미분하여 0이 되는 값을 찾으면 다음과 같다.\n",
    "\n",
    "$$ \\pi_k = \\dfrac{N_k}{N} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babeb33a",
   "metadata": {},
   "source": [
    "이 세가지 식은 모두 responsibility로부터 모수를 구하고 있다.\n",
    "\n",
    "$$ \\pi_{ik} \\;\\; \\implies \\;\\; (\\pi_k, \\mu_k, \\Sigma_k ) $$\n",
    "\n",
    "\n",
    "원래는 연립방정식의 해를 구하는 방법으로 responsibility를 포함한 모수값을 추정해야 한다. 그러나 만약 식의 형태가 responsibility를 알고 있다면 모수를 추정하는 것이 간단하도록 만들어져 있기 때문에 EM(Expectation-Maximization)이라고 하는 iterative 방법을 사용하면 연립방정식의 해를 구하는 것보다 더 쉽게 모수를 추정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b56825",
   "metadata": {},
   "source": [
    "EM 방법은 모수와 responsiblity를 번갈아 추정하며 정확도를 높여가는 방법이다.\n",
    "\n",
    "* E step 에서는 우리가 현재까지 알고 있는 모수가 정확하다고 가정하고 이를 사용하여 각 데이터가 어느 카테고리에 속하는지 즉, responsiblity를 추정한다.\n",
    "\n",
    "$$ (\\pi_k, \\mu_k, \\Sigma_k) \\;\\; \\implies \\;\\; \\pi_{ik} $$\n",
    "\n",
    "* M step 에서는 우리가 현재까지 알고 있는 responsibility가 정확하다고 가정하고 이를 사용하여 모수값을 추정한다.\n",
    "\n",
    "$$ \\pi_{ik} \\;\\; \\implies \\;\\; (\\pi_k, \\mu_k, \\Sigma_k)  $$\n",
    "\n",
    "이를 반복하면 모수와 responsibility를 동시에 점진적으로 개선할 수 있다.\n",
    "\n",
    "\n",
    "각각의 데이터에 대해 responsibility을 알게되면 responsibility가 가장 큰 카테고리를 찾아내어 그 데이터가 어떤 카테고리에 속하는지를 알 수 있다. 즉 클러스터링을 할 수 있다.\n",
    "\n",
    "$$ k_i = \\arg\\max_{k} \\pi_{ik} $$\n",
    "\n",
    "사실 K-means clustering은 EM 방법의 특수한 경우라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf686fd",
   "metadata": {},
   "source": [
    "다음은 파이썬을 이용하여 GMM을 구현하는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_measures_all2 = liq_measures_all.dropna()\n",
    "scaled_liq = StandardScaler().fit_transform(liq_measures_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52393f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(alpha=0.5, bins=50,  stacked=True)\n",
    "plt.hist(liq_measures_all.loc[:, 'percent_quoted_ba'],\n",
    "         **kwargs, label='TC-based')\n",
    "plt.hist(liq_measures_all.loc[:, 'turnover_ratio'],\n",
    "         **kwargs, label='Volume-based')\n",
    "plt.hist(liq_measures_all.loc[:, 'market_impact'],\n",
    "         **kwargs, label='Market-based')\n",
    "plt.title('Multimodality of the Liquidity Measures')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.arange(1, 10)\n",
    "clusters = [GaussianMixture(n, covariance_type='spherical',\n",
    "                            random_state=0).fit(scaled_liq)\n",
    "          for n in n_components]\n",
    "plt.plot(n_components, [m.bic(scaled_liq) for m in clusters])\n",
    "plt.title('Optimum Number of Components')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('BIC values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee26c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_state(data, nstates):\n",
    "    gmm = GaussianMixture(n_components=nstates,\n",
    "                          covariance_type='spherical',\n",
    "                          init_params='kmeans')\n",
    "    gmm_fit = gmm.fit(scaled_liq)\n",
    "    labels = gmm_fit.predict(scaled_liq)\n",
    "    state_probs = gmm.predict_proba(scaled_liq)\n",
    "    state_probs_df = pd.DataFrame(state_probs, \n",
    "                                  columns=['state-1','state-2','state-3'])\n",
    "    state_prob_means = [state_probs_df.iloc[:, i].mean() \n",
    "                        for i in range(len(state_probs_df.columns))]\n",
    "    if np.max(state_prob_means) == state_prob_means[0]:\n",
    "        print('State-1 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[0]))\n",
    "    elif np.max(state_prob_means) == state_prob_means[1]:\n",
    "        print('State-2 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[1]))\n",
    "    else:\n",
    "        print('State-3 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[2]))\n",
    "    return state_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41148b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs = cluster_state(scaled_liq, 3)\n",
    "print(f'State probabilities are {state_probs.mean(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3740fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=11)\n",
    "components = pca.fit_transform(scaled_liq)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('% of Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8588a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_pca(data, nstate):\n",
    "    pca = PCA(n_components=3)\n",
    "    components = pca.fit_transform(data)\n",
    "    mxtd = GaussianMixture(n_components=nstate,\n",
    "                           covariance_type='spherical')\n",
    "    gmm = mxtd.fit(components)\n",
    "    labels = gmm.predict(components)\n",
    "    state_probs = gmm.predict_proba(components)\n",
    "    return state_probs,pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef610512",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs, pca = gmm_pca(scaled_liq, 3)\n",
    "print(f'State probabilities are {state_probs.mean(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpc():\n",
    "    state_probs_df = pd.DataFrame(state_probs,\n",
    "                                  columns=['state-1', 'state-2',\n",
    "                                           'state-3'])\n",
    "    state_prob_means = [state_probs_df.iloc[:, i].mean() \n",
    "                        for i in range(len(state_probs_df.columns))]\n",
    "    if np.max(state_prob_means) == state_prob_means[0]:\n",
    "        print('State-1 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[0]))\n",
    "    elif np.max(state_prob_means) == state_prob_means[1]:\n",
    "        print('State-2 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[1]))\n",
    "    else:\n",
    "        print('State-3 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[2]))\n",
    "wpc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f538d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "loading_matrix = pd.DataFrame(loadings, \n",
    "                              columns=['PC1', 'PC2', 'PC3'],\n",
    "                              index=liq_measures_all.columns)\n",
    "loading_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213db006",
   "metadata": {},
   "source": [
    "## GMCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copulae.mixtures.gmc.gmc import GaussianMixtureCopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dim = scaled_liq.shape\n",
    "gmcm = GaussianMixtureCopula(n_clusters=3, ndim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_fit = gmcm.fit(scaled_liq, method='kmeans',\n",
    "                    criteria='GMCM', eps=0.0001)\n",
    "state_prob = gmcm_fit.params.prob\n",
    "print(f'The state {np.argmax(state_prob) + 1} is likely to occur')\n",
    "print(f'State probabilities based on GMCM are {state_prob}')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
